{
 "metadata": {
  "name": "",
  "signature": "sha256:fa4d6ed9438616a69e90cec4ab670010525401bd22c9c2eecbeef3a1b4169300"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Training layer one\n",
      "\n",
      "This notebook shows how to train a single-layer autoencoder on MNIST using Numpy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import plotting\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load the data\n",
      "\n",
      "First, we download and open the MNIST data set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import gzip\n",
      "import cPickle as pickle\n",
      "import urllib\n",
      "\n",
      "filename = 'mnist.pkl.gz'\n",
      "\n",
      "if not os.path.exists(filename):\n",
      "    url = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'\n",
      "    urllib.urlretrieve(url, filename=filename)\n",
      "\n",
      "with gzip.open(filename, 'rb') as f:\n",
      "    train, valid, test = pickle.load(f)\n",
      "    \n",
      "# use the training set images\n",
      "images = train[0]\n",
      "test_images = test[0]\n",
      "image_shape = (28, 28)\n",
      "assert np.prod(image_shape) == images.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Parameters\n",
      "\n",
      "Next, we define the core parameters for our autoencoder. These include the number of visual and hidden nodes, and the magnitidue of the initial weights."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng = np.random\n",
      "\n",
      "n_vis = images.shape[1]\n",
      "n_hid = 500\n",
      "\n",
      "Wmag = 4 * np.sqrt(6. / (n_vis + n_hid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This autoencoder will have sparse weights, i.e. each neuron has a limited receptive field. To accomplish this, we create a mask that denotes the non-zero weights."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_shape = (9, 9)\n",
      "M, N = image_shape\n",
      "m, n = rf_shape\n",
      "\n",
      "# find random positions for top-left corner of each RF\n",
      "i = rng.randint(low=0, high=M-m+1, size=n_hid)\n",
      "j = rng.randint(low=0, high=N-n+1, size=n_hid)\n",
      "\n",
      "mask = np.zeros((M, N, n_hid), dtype='bool')\n",
      "for k in xrange(n_hid):\n",
      "    mask[i[k]:i[k]+m, j[k]:j[k]+n, k] = True\n",
      "\n",
      "mask = mask.reshape(n_vis, n_hid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Neural nonlinearity\n",
      "\n",
      "We will begin by using the traditional logistic sigmoid function for our nonlinearity. We need to define both the function and its derivative; the derivative is used as part of the backpropagation algorithm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logistic(x):\n",
      "    return 1. / (1 + np.exp(-x))\n",
      "\n",
      "def d_logistic(x):\n",
      "    y = logistic(x)\n",
      "    return y * (1 - y)\n",
      "\n",
      "x = np.linspace(-5, 5, 101)\n",
      "plt.plot(x, logistic(x))\n",
      "plt.plot(x, d_logistic(x));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Train the RBM using backpropagation\n",
      "\n",
      "We can now train the autoencoder using the backpropagation algorithm. We define the number of epochs, where each epoch goes through the training set once. We also divide the training set into mini-batches, where the gradient is updated after each mini-batch.\n",
      "\n",
      "We define the learning rate, a cost on large-magnitude weights, and the momentum. The momentum allows smoothing over the gradient estimates of many mini-batches, and may also help avoid local minima. To implement momentum, we need to track the last increments of the weights and biases (`Winc`, `cinc`, `binc`).\n",
      "\n",
      "We also initialize the weights and biases themselves. The weights are initialized randomly, and the biases are initialized to zero.\n",
      "\n",
      "Our autoencoder uses \"tied\" weights, which means that the same weights are used to compute the hidden layer activations and to reconstruct the visual layer inputs. The basic structure is\n",
      "\n",
      "$$y_j = f\\left(\\sum_i x_i W_{ij} + c_j \\right)$$\n",
      "$$z_i = \\sum_j y_j W_{ij} + b_i$$\n",
      "\n",
      "Where $f$ is our nonlinearity, $y_j$ is the activation of hidden node $j$, and $z_i$ is the reconstruction of hidden node $x_i$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train(f, df, n_epochs=5, rate=0.1, noise=0):\n",
      "    \"\"\" Train a (denoising) autoencoder.\n",
      "    \n",
      "    Our function takes in a nonlinearity and its derivative, as well as some parameters.\n",
      "    \"\"\"\n",
      "    \n",
      "    batch_size = 100\n",
      "    batches = images.reshape(-1, batch_size, images.shape[1])\n",
      "\n",
      "    weightcost = 2e-4\n",
      "    momentum = 0.5\n",
      "\n",
      "    W = rng.uniform(low=-Wmag, high=Wmag, size=(n_vis, n_hid)) * mask\n",
      "    c = np.zeros(n_hid)\n",
      "    b = np.zeros(n_vis)\n",
      "\n",
      "    Winc = np.zeros_like(W)\n",
      "    cinc = np.zeros_like(c)\n",
      "    binc = np.zeros_like(b)\n",
      "\n",
      "    for epoch in range(n_epochs):\n",
      "\n",
      "        # train on each mini-batch\n",
      "        costs = []\n",
      "        for batch in batches:\n",
      "            x = batch\n",
      "            \n",
      "            # add noise if desired (see discussion of denoising autoencoders below)\n",
      "            if noise > 0:\n",
      "                xn = x + rng.normal(scale=noise, size=batch.shape)\n",
      "            else:\n",
      "                xn = x\n",
      "\n",
      "            # compute the hidden layer activation\n",
      "            a = np.dot(xn, W) + c\n",
      "            y = f(a)\n",
      "            \n",
      "            # compute the visual layer reconstruction\n",
      "            z = np.dot(y, W.T) + b\n",
      "\n",
      "            # compute the cost\n",
      "            r = (0.5 / batch_size) * ((z - x)**2).sum()\n",
      "\n",
      "            # compute the gradients\n",
      "            dr_dz = (z - x) / batch_size\n",
      "            dr_da = np.dot(dr_dz, W) * df(a)\n",
      "            \n",
      "            # the W gradient has two parts:\n",
      "            # the first is for the direct effect of 'W.T' on 'z'\n",
      "            # and the second is for the effect of 'W' on 'a'.\n",
      "            dr_dw = np.dot(dr_dz.T, y) + np.dot(x.T, dr_da)\n",
      "            \n",
      "            dr_dc = dr_da.sum(axis=0)\n",
      "            dr_db = dr_dz.sum(axis=0)\n",
      "\n",
      "            # compute updates by moving in the opposite direction of the gradient\n",
      "            # (since we want to minimize the error)\n",
      "            Winc = momentum * Winc + rate * (-dr_dw - weightcost * W)\n",
      "            cinc = momentum * cinc + rate * (-dr_dc)\n",
      "            binc = momentum * binc + rate * (-dr_db)\n",
      "\n",
      "            W += Winc * mask\n",
      "            c += cinc\n",
      "            b += binc\n",
      "\n",
      "            costs.append(r)\n",
      "\n",
      "        print \"Epoch %d: %0.3f\" % (epoch, np.mean(costs))\n",
      "        \n",
      "    return W, c, b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "W, c, b = train(f=logistic, df=d_logistic, noise=0)\n",
      "encode = lambda x: logistic(np.dot(x, W) + c)\n",
      "decode = lambda y: np.dot(y, W.T) + b\n",
      "\n",
      "# --- plot reconstructions on test set\n",
      "plt.figure(2)\n",
      "plt.clf()\n",
      "codes = encode(test_images)\n",
      "recons = decode(codes)\n",
      "plotting.compare(\n",
      "    [test_images.reshape(-1, *image_shape),\n",
      "     recons.reshape(-1, *image_shape)],\n",
      "    rows=3, cols=10)\n",
      "\n",
      "# --- plot filters\n",
      "plt.figure(3)\n",
      "plt.clf()\n",
      "filters = W.T[mask.T].reshape(n_hid, *rf_shape)\n",
      "plotting.filters(filters, rows=5, cols=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output shows the cost at each epoch. The cost decreases as the autoencoder learns to better represent the training data.\n",
      "\n",
      "The first plot shows test digits on the top and their reconstructions (i.e. encoding then decoding) right below. The reconstructions are very accurate, suggesting that the autoencoder has successfully learned to represent the test set.\n",
      "\n",
      "The final plot shows some of the filters (columns of the W matrix) that the autoencoder has learned. These filters can be thought of as \"features\" that the autoencoder is detecting, for the purpose of representing (or encoding) the input."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Denoising autoencoders\n",
      "\n",
      "One observation about the autoencoder that we just learned is that the features look quite noisy. In mammals, we often think of the early visual system as detecting oriented edges, as first observed by Hubel and Wiesel. We expect the filters for such neurons to be smoother and more edge-like.\n",
      "\n",
      "To produce smoother filters, we can train a *denoising* autoencoder. This autoencoder takes a noisy version of the input, and tries to reconstruct the noise-free version. Such an autoencoder should be more robust to noise than the one we just trained.\n",
      "\n",
      "First, we need to determine how much noise to add. Let's add some noise and see how it looks:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = images[:30]\n",
      "xn = x + rng.normal(scale=0.3, size=x.shape)\n",
      "plotting.compare([x.reshape(-1, *image_shape), xn.reshape(-1, *image_shape)], \n",
      "                 rows=3, cols=10, vlims=[0, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "The images are clearly noisier, but still quite legible, so our autoencoder should be able to handle them."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "W, c, b = train(f=logistic, df=d_logistic, noise=0.3)\n",
      "encode = lambda x: logistic(np.dot(x, W) + c)\n",
      "decode = lambda y: np.dot(y, W.T) + b\n",
      "\n",
      "# --- plot reconstructions on test set\n",
      "plt.figure(2)\n",
      "plt.clf()\n",
      "codes = encode(test_images)\n",
      "recons = decode(codes)\n",
      "\n",
      "noisy_codes = encode(test_images + rng.normal(scale=0.3, size=test_images.shape))\n",
      "noisy_recons = decode(noisy_codes)\n",
      "\n",
      "plotting.compare(\n",
      "    [test_images.reshape(-1, *image_shape),\n",
      "     recons.reshape(-1, *image_shape),\n",
      "     noisy_recons.reshape(-1, *image_shape)],\n",
      "    rows=3, cols=10, vlims=(0, 1))\n",
      "\n",
      "# --- plot filters\n",
      "plt.figure(3)\n",
      "plt.clf()\n",
      "filters = W.T[mask.T].reshape(n_hid, *rf_shape)\n",
      "plotting.filters(filters, rows=5, cols=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The filters that we have learned are now much smoother than before, and many of them look like parts of digits (lines and smooth curves)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training with other response functions\n",
      "\n",
      "We want to train with neural response functions, so that we can use the learned weights and biases with spiking LIF neurons. To do this, we train with the soft LIF function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from neurons import get_numpy_fn, get_numpy_deriv\n",
      "params = dict(tau_rc=0.02, tau_ref=0.002, gain=1, bias=1, amp=1)\n",
      "sparams = dict(params.items() + dict(sigma=0.1).items())\n",
      "\n",
      "lif = get_numpy_fn('lif', params)\n",
      "d_lif = get_numpy_deriv('lif', params)\n",
      "softlif = get_numpy_fn('softlif', sparams)\n",
      "d_softlif = get_numpy_deriv('softlif', sparams)\n",
      "\n",
      "x = np.linspace(-3, 3, 101)\n",
      "plt.figure(figsize=(12, 6))\n",
      "plt.subplot(121)\n",
      "plt.plot(x, lif(x), label='lif')\n",
      "plt.plot(x, softlif(x), label='softlif')\n",
      "plt.legend(loc=2)\n",
      "plt.xlabel('input')\n",
      "plt.ylabel('firing rate [Hz]')\n",
      "plt.subplot(122)\n",
      "plt.plot(x, d_lif(x))\n",
      "plt.plot(x, d_softlif(x))\n",
      "plt.xlabel('input')\n",
      "plt.ylabel('firing rate derivative');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even though the soft LIF function has a much smoother derivative than the LIF function, it is still more extreme than the sigmoid derivative. So we have to use a smaller learning rate to avoid having the derivative get too large, especially at the beginning of the training. This also means we have to train for longer to get the same effect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = dict(tau_rc=0.02, tau_ref=0.002, gain=1, bias=1, amp=0.063)\n",
      "sparams = dict(params.items() + dict(sigma=0.1).items())\n",
      "\n",
      "lif = get_numpy_fn('lif', params)\n",
      "d_lif = get_numpy_deriv('lif', params)\n",
      "softlif = get_numpy_fn('softlif', sparams)\n",
      "d_softlif = get_numpy_deriv('softlif', sparams)\n",
      "\n",
      "W, c, b = train(f=softlif, df=d_softlif, n_epochs=15, rate=0.01, noise=0.3)\n",
      "\n",
      "# reconstruct using softlif (as trained)\n",
      "encode = lambda x: softlif(np.dot(x, W) + c)\n",
      "decode = lambda y: np.dot(y, W.T) + b\n",
      "codes = encode(test_images)\n",
      "recons = decode(codes)\n",
      "\n",
      "# reconstruct with lif instead of softlif\n",
      "encode = lambda x: lif(np.dot(x, W) + c)\n",
      "codes = encode(test_images)\n",
      "recons_lif = decode(codes)\n",
      "\n",
      "# --- plot reconstructions on test set\n",
      "plt.figure(2)\n",
      "plt.clf()\n",
      "plotting.compare(\n",
      "    [test_images.reshape(-1, *image_shape),\n",
      "     recons.reshape(-1, *image_shape),\n",
      "     recons_lif.reshape(-1, *image_shape)],\n",
      "    rows=3, cols=10)\n",
      "\n",
      "# --- plot filters\n",
      "plt.figure(3)\n",
      "plt.clf()\n",
      "filters = W.T[mask.T].reshape(n_hid, *rf_shape)\n",
      "plotting.filters(filters, rows=5, cols=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing to notice is that the network is still able to reconstruct the digits when using LIF neurons instead of soft LIF neurons (as it was trained), but the reconstructions aren't quite as good. We can alleviate this by training for longer, and relaxing the soft LIF curve as we go to become more like the LIF curve.\n",
      "\n",
      "You may also notice that the filters learned here do not look as smooth as before. This is mostly due to the fact that we used one tenth the learning rate as before, but only increased the number of epochs by a factor of three, so the network really hasn't had sufficient time to train."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}